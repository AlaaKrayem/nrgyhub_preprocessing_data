{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import copy\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "import string\n",
    "import os, sys, getpass\n",
    "import io, uuid\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Common folders and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "table_source = \"C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/TABLES\"\n",
    "attributes_source = \"C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet\"\n",
    "stad_source = \"C:/Users/akm03/Alaa/NERGYHUB/data/vasteras_stad/processed_data\"\n",
    "\n",
    "\n",
    "min_height = 2.4\n",
    "min_volume = 3.2\n",
    "\n",
    "# common names of files that will be used\n",
    "raw_buildings = 'buildings_filtered'\n",
    "final_buildings = \"buildings\"\n",
    "\n",
    "raw_properties = \"ay_riks_updated\"\n",
    "final_properties = 'properties'\n",
    "\n",
    "raw_addresses = 'ADRPL_90A.xlsx'\n",
    "final_addresses = 'addresses'\n",
    "\n",
    "height_on_perimeter = 'dtm_values_at_perimeters.csv'\n",
    "\n",
    "\n",
    "#final_file = 'joined_buildings_addresses_properties'\n",
    "\n",
    "### open attribute table that will be use to specify columns to keep and their new names\n",
    "data_list = os.path.join(attributes_source, \"data_list.xlsx\")\n",
    "\n",
    "attributes_sheet_name = \"Attributes_description\"\n",
    "attributes = pd.read_excel(data_list, attributes_sheet_name)\n",
    "\n",
    "codes_sheet_name = \"Codes\"\n",
    "codes = pd.read_excel(data_list, codes_sheet_name)\n",
    "\n",
    "options_sheet_name = \"Attributes_options\"\n",
    "options = pd.read_excel(data_list, options_sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "city_name = 'Vasteras'\n",
    "\n",
    "input_dtm = 'C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/{}/DTM/at_perimeters'.format(city_name)\n",
    "input_dsm = 'C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/{}/DSM/at_perimeters'.format(city_name)\n",
    "input_dsm_pixel = 'C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/{}/DSM/at_buildings'.format(city_name)\n",
    "\n",
    "destination = \"C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/{0}/processed_data\".format(city_name)\n",
    "source = \"C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/{0}/Fastighetskartan\".format(city_name)\n",
    "\n",
    "# extent = gpd.read_file(os.path.join(destination, 'properties_extent.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_duplication(df, column = None, drop = False, **kwargs):    \n",
    "    if column and column not in df.columns:\n",
    "        print('Column {} does not exist in dataframe'.format(column))\n",
    "    else:\n",
    "        if column is None:\n",
    "            column = list(df.columns)   \n",
    "        df_duplicated = df.loc[df[column].duplicated(), :]\n",
    "        if len(df_duplicated)>0:    \n",
    "            print(len(df_duplicated[column].values.tolist()))\n",
    "            #print(df_duplicated[column].values.tolist())\n",
    "            if drop:\n",
    "                #print(kwargs)\n",
    "                df.drop_duplicates(subset = column, **kwargs)\n",
    "                return df\n",
    "        else:\n",
    "            print(\"No duplications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Convert addresses from tables to a shapefile (already run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # set the table source as the directory\n",
    "# os.chdir(table_source)\n",
    "# sheetname = 'Data'\n",
    "# # read file\n",
    "# addresses_table = pd.read_excel(raw_addresses, sheet_name = sheetname)\n",
    "# # use deep copy to reduce loading time of the data especially when debugging the code\n",
    "# addresses = copy.deepcopy(addresses_table)\n",
    "# # remove rows with no value for POSTNR because it is not a building\n",
    "# addresses = addresses[addresses['POSTNR'].notnull()]\n",
    "\n",
    "# #### convert file to geopandas\n",
    "# from geopandas import GeoDataFrame\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# Xcoord = 'YKOORD'\n",
    "# Ycoord = 'XKOORD'\n",
    "# XcoordL = 'YKOORDL'\n",
    "# YcoordL = 'XKOORDL'\n",
    "\n",
    "# geometry = [Point(xy) for xy in zip(addresses[Xcoord], addresses[Ycoord])]\n",
    "# addresses = addresses.drop([Xcoord, Ycoord, XcoordL, YcoordL], axis=1)\n",
    "# addresses = GeoDataFrame(addresses, crs=\"EPSG:3006\", geometry=geometry)\n",
    "\n",
    "# # Save as shapefile\n",
    "# addresses.to_file(final_addresses + '.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Buildings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set the destination as the directory\n",
    "os.chdir(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#################### read the building file for curation\n",
    "buildings = gpd.read_file(raw_buildings + \".shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings = pd.read_excel(raw_buildings + \".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculate height as the difference between the average DTM and maximum DSM\n",
    "buildings['Height'] = buildings['DSM_max'] - buildings['DTM_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Some buildings will have less than 2.4 m height which is incorrect. That means that this method has a certain uncertainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate the percentage of builidngs with a height < 2.4 and set their height to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check values range\n",
    "print(buildings[['Height']].describe())\n",
    "buildLessThan2o2 = buildings.loc[buildings['Height']<min_height, 'Height']\n",
    "buildLessThan2o2.hist(bins=20)\n",
    "print('Number of builidngs with abnormal height : {0}'.format(len(buildLessThan2o2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "percBuildLessThan2o2 = len(buildLessThan2o2)/len(buildings)*100\n",
    "print('Percentage of buildings with abnormal height :{0} %'.format(round(percBuildLessThan2o2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the heught of these buildings to Nan\n",
    "buildings.loc[buildings['Height']<min_height, 'Height'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Delete/rename buildings shapefiles columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get buildings attributes only\n",
    "attributes_buildings = attributes[attributes['Feature']=='Buildings']\n",
    "updated_columns = []\n",
    "for col in buildings.columns:\n",
    "    j = attributes_buildings['Attribute'].tolist().index(col)\n",
    "    updated_columns.append(attributes_buildings['NewName'].tolist()[j])\n",
    "drop_columns = [col for col in buildings.columns if updated_columns[buildings.columns.tolist().index(col)] == 'REMOVE']\n",
    "updated_columns = [i for i in updated_columns if i != 'REMOVE']\n",
    "buildings.drop(drop_columns, inplace=True, axis=1)\n",
    "buildings.columns = updated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# replace Type values by their english synonyms for data_file, options sheet\n",
    "# swedish list\n",
    "swedish = options[options['Attribute']=='DETALJTYP']['Purpose'].tolist()\n",
    "english = options[options['Attribute']=='DETALJTYP']['Definition'].tolist()\n",
    "buildings['Type'] = buildings['Type'].replace(swedish, english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def purpose(x, codes_list, purposes_list, column_name):\n",
    "    j = codes_list.index(x[column_name])\n",
    "    return purposes_list[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add Purpose and Details columns that give information about the building purpose based on its code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read codes list from data list, codes sheet\n",
    "#code column name\n",
    "code_column = 'Code'\n",
    "\n",
    "codes_list = codes[code_column].tolist()\n",
    "purposes_list = codes['Purpose'].tolist()\n",
    "detailed_purposes_list = codes['Details'].tolist()\n",
    "buildings['Purpose'] = buildings.apply(lambda x: purpose(x, codes_list, purposes_list, code_column), axis = 1)\n",
    "buildings['Details'] = buildings.apply(lambda x: purpose(x, codes_list, detailed_purposes_list, code_column), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check the units of the shapefile\n",
    "print(buildings.crs.axis_info[0].unit_name)\n",
    "# add area field; convert if unit is not meter\n",
    "buildings['Area'] = buildings.geometry.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Buildings volumes\n",
    "The buildings volumes to be calculated by multiplying the area with the height on the perimeter. It is calculated in 1_nrgyhub_qgis jupyter notebook. Load the resulted file to calculate the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "heightsPerimeter = pd.read_csv(os.path.join('C:/Users/akm03/Alaa/NERGYHUB/data/lantmateriet/Vasteras/DSM/las2dempro/at_deeper_perimeters', \"dsm_values_at_perimeters.csv\"))\n",
    "#heightsPerimeter.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "check_duplication(heightsPerimeter, column = 'ID', drop = True, \n",
    "                                     keep = 'first', inplace = True, ignore_index = True)\n",
    "\n",
    "# concatenate files based on building id\n",
    "buildings = buildings.merge(heightsPerimeter, how='left', left_on='BuildingID', right_on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check columns and drop redundant varibales\n",
    "print(buildings.columns)\n",
    "\n",
    "# calculate volume\n",
    "buildings['Height2'] = buildings['Value']-buildings['DTM_mean']\n",
    "buildings.loc[buildings['Height2']<min_height, 'Height2'] = np.nan\n",
    "buildings['Volume'] = buildings['Area']*buildings['Height2']\n",
    "buildings.drop(columns = ['ID', 'Value'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Some buildings have negative values and less than 3.2 m3. If height != 0, replace volume by height*area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings['Volume2'] = buildings['Height'] * buildings['Area']\n",
    "buildings.loc[(buildings['Volume']<min_volume)&(buildings['Height']!=0), 'Volume'] = buildings.loc[(buildings['Volume']<min_volume)&(buildings['Height']!=0), 'Volume2']\n",
    "buildings.loc[buildings['Volume']<min_volume, 'Volume'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings.drop(columns = ['Volume2'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def freedman_diaconis(data, returnas=\"width\"):\n",
    "    data = np.asarray(data, dtype=np.float_)\n",
    "    IQR  = stats.iqr(data, rng=(25, 75), scale=\"raw\", nan_policy=\"omit\")\n",
    "    N    = data.size\n",
    "    bw   = (2 * IQR) / np.power(N, 1/3)\n",
    "\n",
    "    if returnas==\"width\":\n",
    "        result = bw\n",
    "    else:\n",
    "        datmin, datmax = data.min(), data.max()\n",
    "        datrng = datmax - datmin\n",
    "        result = int((datrng / bw) + 1)\n",
    "    return(result)\n",
    "\n",
    "def plot_hist(ID, df):\n",
    "    df = df.loc[df['ID']==ID,'Value']\n",
    "    print(df.min(), df.max(), df.median(), df.mean())\n",
    "    fig, ax = plt.subplots(figsize = (6,4))\n",
    "    # Plot histogram\n",
    "    #df.plot(kind = \"hist\", density = True, bins = 20, grid=True,) # change density to true, because KDE uses density\n",
    "    ax.hist(df, bins=freedman_diaconis(df, returnas = 'bins'), density = True)\n",
    "    # Plot KDE\n",
    "    df.plot(kind = \"kde\")\n",
    "    \n",
    "    # non-parametric pdf\n",
    "    nparam_density = stats.kde.gaussian_kde(df.ravel())\n",
    "    x = np.linspace(-20, max(df)+20, 500)\n",
    "    nparam_density = nparam_density(x)\n",
    "    #ax.plot(x, nparam_density, 'r-', label='non-parametric density (smoothed by Gaussian kernel)')\n",
    "    \n",
    "#     # Calculate percentiles\n",
    "#     quant_5, quant_25, quant_50, quant_75, quant_95 = df.quantile(0.05), df.quantile(0.25), df.quantile(0.5), df.quantile(0.75), df.quantile(0.95)\n",
    "#     # [quantile, opacity, length]\n",
    "#     quants = [[quant_5, 0.6, 0.16], [quant_25, 0.8, 0.26], [quant_50, 1, 0.36],  [quant_75, 0.8, 0.46], [quant_95, 0.6, 0.56]]\n",
    "#     # Plot the lines with a loop\n",
    "#     for i in quants:\n",
    "#         ax.axvline(i[0], alpha = i[1], ymax = i[2], linestyle = \":\")\n",
    "        \n",
    "    # X #\n",
    "    ax.set_xlabel(\"Pixel Height (m)\")\n",
    "    ax.set_xlim(round(df.max())-5, round(df.max())+5)\n",
    "    # Y #\n",
    "    #ax.set_ylim(0, 2)\n",
    "    #ax.set_yticks([])\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "    \n",
    "    # Annotations\n",
    "#     ax.text(quant_5-.1, 0.17, \"5th\", size = 10, alpha = 0.8)\n",
    "#     ax.text(quant_25-.13, 0.27, \"25th\", size = 11, alpha = 0.85)\n",
    "#     ax.text(quant_50-.13, 0.37, \"50th\", size = 12, alpha = 1)\n",
    "#     ax.text(quant_75-.13, 0.47, \"75th\", size = 11, alpha = 0.85)\n",
    "#     ax.text(quant_95-.25, 0.57, \"95th Percentile\", size = 10, alpha =.8)\n",
    "    \n",
    "    # Overall #\n",
    "    #ax.grid(False)\n",
    "    ax.set_title(\"Building #{}\".format(ID))\n",
    "\n",
    "    # Remove ticks and spines\n",
    "    #ax.tick_params(left = False, bottom = False)\n",
    "    #for ax, spine in ax.spines.items():\n",
    "     #   spine.set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Add NYKO3 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buildings = gpd.read_file(final_buildings + '.shp')\n",
    "buildings.drop(columns = 'NYKO3', inplace = True)\n",
    "\n",
    "nyko3 = gpd.read_file(os.path.join(stad_source, 'NYKO3.shp'))\n",
    "nyko3 = nyko3.loc[:, ['NYKO3', 'NAMN', 'Shape_Leng', 'Shape_Area', 'geometry']]\n",
    "nyko3 = nyko3.to_crs('epsg:3006')\n",
    "\n",
    "centroids = buildings.copy()\n",
    "centroids.loc[:, 'geometry'] = buildings.loc[:'geometry'].centroid\n",
    "centroids_in_nyko = gpd.sjoin(centroids, nyko3, op='within', how = 'left')\n",
    "\n",
    "centroids_in_nyko['geometry'] = buildings['geometry']\n",
    "columns_to_keep = list(buildings) + ['NYKO3']\n",
    "buildings = centroids_in_nyko[columns_to_keep]\n",
    "buildings['NYKO3'] = buildings['NYKO3'].astype(str)\n",
    "\n",
    "# save file\n",
    "buildings.to_file(final_buildings + '.shp')\n",
    "buildings.to_excel(final_buildings + '.xlsx')\n",
    "buildings = buildings.to_crs(epsg=4326)\n",
    "buildings.to_file(final_buildings + '.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check for duplicated records and keep only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check if any record is duplicated; returns all rows \n",
    "check_duplication(buildings, drop = False, inplace = True, ignore_index = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "check_duplication(buildings, column = 'BuildingID')  \n",
    "\n",
    "# Since there are duplicated buildingID, a new one will be created.\n",
    "buildings['BuildingID'] = range(1, 1 + len(buildings))\n",
    "#buildings['BuildingID'] = buildings.index + 1\n",
    "#buildings.drop(columns = 'BuildingID', inplace = True)\n",
    "check_duplication(buildings, column = 'BuildingID')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(buildings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data from data folder to ArcGIS connected folder\n",
    "for files in os.listdir(source):\n",
    "    name = os.path.splitext(os.path.basename(files))\n",
    "    if (raw_properties in files)&(final_properties+name[1] not in os.listdir(destination)):\n",
    "        shutil.copy(os.path.join(source, files), os.path.join(destination, files))\n",
    "        \n",
    "# rename the files in the destination folder\n",
    "for files in os.listdir(destination):\n",
    "    name = os.path.splitext(os.path.basename(files))\n",
    "    if (raw_properties in files)&(final_properties+name[1] not in os.listdir(destination)):\n",
    "        name = os.path.splitext(os.path.basename(files))\n",
    "        os.rename(os.path.join(destination, files), os.path.join(destination, final_properties+name[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the destination as the directory\n",
    "os.chdir(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### load data to process\n",
    "properties = gpd.read_file(final_properties+'.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entries with FNR = 0\n",
    "# properties = properties[properties['FNR_FDS']!='0']\n",
    "len(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplication(properties, drop = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### look for duplicates because of value 2 in YTKVAL where a property geometry can have a duplicate geometrically and \n",
    "#### in some fields\n",
    "#properties.drop(columns=['FNR_FDS', 'OBJEKT_ID','FASTIGHET', 'OMRTYP','EXTERNID'], inplace = True)\n",
    "\n",
    "#### Drop duplicated geometrical properties\n",
    "# convert to wkb\n",
    "properties[\"geometry\"] = properties[\"geometry\"].apply(lambda geom: geom.wkb)\n",
    "check_duplication(properties, column = 'geometry', drop = False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A number of properties have the same geometries; keep only the last updated one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = properties.sort_values(by = 'ADAT', ascending = False).drop_duplicates([\"geometry\"], keep = 'first')\n",
    "# convert back to shapely geometry\n",
    "properties[\"geometry\"] = properties[\"geometry\"].apply(lambda geom: shapely.wkb.loads(geom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, some records have the same FNR_FDS field, or OBJECKT_ID. That is because the file is property areas so a property may have many areas. Create new uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete/rename propeties shapefiles columns\n",
    "# get properties attributes only\n",
    "attributes_properties = attributes[attributes['File']=='riks']\n",
    "updated_columns = []\n",
    "drop_columns = []\n",
    "for col in properties.columns:\n",
    "    j = attributes_properties['Attribute'].tolist().index(col)\n",
    "    updated_columns.append(attributes_properties['NewName'].tolist()[j])\n",
    "drop_columns = [col for col in properties.columns if updated_columns[properties.columns.tolist().index(col)] == 'REMOVE']\n",
    "updated_columns = [i for i in updated_columns if i != 'REMOVE']\n",
    "properties.drop(drop_columns, inplace=True, axis=1)\n",
    "properties.columns = updated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are duplicated propertyID, a new one will be created.\n",
    "#properties['PropertyID'] = properties.index + 1\n",
    "properties['PropertyID'] = range(1, 1 + len(properties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add more info from Lantmäteriet table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the table source as the directory\n",
    "os.chdir(table_source)\n",
    "raw_info = 'VESHBYGG_43O.xlsx'\n",
    "sheetname = 'Data'\n",
    "# read file\n",
    "info_table = pd.read_excel(raw_info, sheet_name = sheetname)\n",
    "# use deep copy to reduce loading time of the data especially when debugging the code\n",
    "info = copy.deepcopy(info_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['FNR'] = info['FNR'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = info[['FNR','YTABOST','YTABI','YTAVARDE','BYGGAR']]\n",
    "info.columns = ['FNR','Boyta', 'Biarea', 'TotalArea', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = properties.merge(info,how='left', on = 'FNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD NYKO3 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties = gpd.read_file(final_properties + '.shp')\n",
    "# properties.drop(columns = 'NYKO3', inplace = True)\n",
    "# properties = properties.to_crs('epsg:3006')\n",
    "\n",
    "nyko3 = gpd.read_file(os.path.join(stad_source, 'NYKO3.shp'))\n",
    "nyko3 = nyko3.loc[:, ['NYKO3', 'NAMN', 'Shape_Leng', 'Shape_Area', 'geometry']]\n",
    "nyko3 = nyko3.to_crs('epsg:3006')\n",
    "\n",
    "centroids = properties.copy()\n",
    "centroids.loc[:, 'geometry'] = properties.loc[:'geometry'].centroid\n",
    "centroids_in_nyko = gpd.sjoin(centroids, nyko3, op='within', how = 'left')\n",
    "\n",
    "centroids_in_nyko['geometry'] = properties['geometry']\n",
    "columns_to_keep = list(properties) + ['NYKO3']\n",
    "properties = centroids_in_nyko[columns_to_keep]\n",
    "properties['NYKO3'] = properties['NYKO3'].astype(str)\n",
    "\n",
    "# save file\n",
    "# properties.to_file(final_properties + '.shp')\n",
    "# properties.to_excel(final_properties + '.xlsx')\n",
    "# properties = properties.to_crs(epsg=4326)\n",
    "# properties.to_file(final_properties + '.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Addresses data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set the table source as the directory\n",
    "os.chdir(table_source)\n",
    "#################### load data to process\n",
    "addresses = gpd.read_file(final_addresses+'.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# select only addresses within properties extent\n",
    "polygon = extent.geometry[0]\n",
    "addresses = addresses[addresses.within(polygon)]\n",
    "len(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "addresses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# delete/rename addresses shapefiles columns\n",
    "# get addresses attributes only\n",
    "attributes_addresses = attributes[attributes['File']=='ADRPL_90A']\n",
    "updated_columns = []\n",
    "drop_columns = []\n",
    "for col in addresses.columns:\n",
    "    j = attributes_addresses['Attribute'].tolist().index(col)\n",
    "    updated_columns.append(attributes_addresses['NewName'].tolist()[j])\n",
    "drop_columns = [col for col in addresses.columns if updated_columns[addresses.columns.tolist().index(col)] == 'REMOVE']\n",
    "updated_columns = [i for i in updated_columns if i != 'REMOVE']\n",
    "addresses.drop(drop_columns, inplace=True, axis=1)\n",
    "addresses.columns = updated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#### Drop duplicated geometrical addresses\n",
    "# convert to wkb\n",
    "addresses[\"geometry\"] = addresses[\"geometry\"].apply(lambda geom: geom.wkb)\n",
    "check_duplication(addresses, drop = False)\n",
    "# convert back to shapely geometry\n",
    "addresses[\"geometry\"] = addresses[\"geometry\"].apply(lambda geom: shapely.wkb.loads(geom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add Block and Enhet fields from REGENH tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.chdir(table_source)\n",
    "# add Block and Enhet \n",
    "blocks_pd = []\n",
    "# get filenames\n",
    "for s in ['A','B','C']:\n",
    "    addresses_file = 'REGENH_01%s.xlsx'%s\n",
    "    sheetname = 'Data'\n",
    "    # read file\n",
    "    addresses_pd = pd.read_excel(addresses_file, sheet_name = sheetname)\n",
    "    blocks_pd.append(addresses_pd)\n",
    "blocks = pd.concat(blocks_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# delete/rename blocks shapefiles columns\n",
    "# get blocks attributes only\n",
    "attributes_blocks = attributes[attributes['File']=='REGENH_01']\n",
    "updated_columns = []\n",
    "drop_columns = []\n",
    "for col in blocks.columns:\n",
    "    j = attributes_blocks['Attribute'].tolist().index(col)\n",
    "    updated_columns.append(attributes_blocks['NewName'].tolist()[j])\n",
    "drop_columns = [col for col in blocks.columns if updated_columns[blocks.columns.tolist().index(col)] == 'REMOVE']\n",
    "updated_columns = [i for i in updated_columns if i != 'REMOVE']\n",
    "blocks.drop(drop_columns, inplace=True, axis=1)\n",
    "blocks.columns = updated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# merge addresses and blocks\n",
    "addresses = addresses.merge(blocks,how='left', left_on='UUIDREGENH', right_on='UUID')\n",
    "addresses.drop(columns = ['UUIDREGENH','UUID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check coordinates systems and porject if necessary\n",
    "print('Addresses CRS: ', addresses.crs)\n",
    "#addresses  = addresses.to_crs('epsg:3006')\n",
    "#print('Addresses CRS: ', addresses.crs)\n",
    "#addressesShp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save properties shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set the destination as the directory\n",
    "os.chdir(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "properties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "properties['FNR'] = properties['FNR'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "properties.Commune.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "check_duplication(properties.loc[properties['Commune']=='1980', :], column = 'FNR', drop = False, \n",
    "                                     keep = 'first', inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# when done move it to Properties section above\n",
    "buildings = gpd.read_file(final_buildings + \".shp\")\n",
    "properties_duplicated = properties.loc[properties['FNR'].duplicated(), :]\n",
    "buildings = buildings.loc[buildings['PropertyID'].isin(properties_duplicated['PropertyID'].unique().tolist()), :]\n",
    "buildings.to_file('testing.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_obj = properties.select_dtypes(['object'])\n",
    "properties[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# write the new properties shapefile\n",
    "properties.to_file(final_properties + '.shp')\n",
    "properties.to_excel(final_properties + '.xlsx')\n",
    "properties = properties.to_crs(epsg=4326)\n",
    "properties.to_file(final_properties + '.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save buildings shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert type of id to float to make it possible to link addresses id to buildings id as database tables. Otherwise\n",
    "# nan id won't be accepted\n",
    "# buildings['BuildingID'] = buildings['BuildingID'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### add street address to buildings. \n",
    "# addressesInbuildings = gpd.sjoin(addresses, buildings, op='within')\n",
    "# addressesInbuildings.sort_index(inplace=True)\n",
    "# addressesInbuildings = addressesInbuildings.drop(['index_right'], axis=1)\n",
    "\n",
    "# check_duplication(addressesInbuildings, column = 'BuildingID', drop = True, \n",
    "#                                      keep = 'first', inplace = True, ignore_index = True)\n",
    "\n",
    "# # add street, zip code, number to buildings\n",
    "# columns_to_add = ['Street','Municipal','PostNb','PostOffice', 'BuildingID']# 'AdrPlace','AdrPlaceTp','County','Commune','AdrAreaTp',\n",
    "# buildingsWithaddresses = buildings.merge(addressesInbuildings[columns_to_add],how='left', left_on='BuildingID', right_on='BuildingID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "properties = properties.to_crs(epsg=3006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### because of limitation in the spatial join, we use the buildings centroids \n",
    "buildingsWithaddresses = buildings.copy()\n",
    "\n",
    "buildings_centroids = buildingsWithaddresses.copy()\n",
    "buildings_centroids['geometry'] =  buildings_centroids['geometry'].centroid\n",
    "\n",
    "buildingsInproperties = gpd.sjoin(buildings_centroids, properties, op='within')\n",
    "#buildingsInproperties.reset_index(inplace=True, drop=True)\n",
    "buildingsInproperties.sort_index(inplace = True)\n",
    "#buildingsInproperties['Commune'] = buildingsInproperties['Commune_left'] \n",
    "#buildingsInproperties['Municipal'] = buildingsInproperties['Municipal_left'] \n",
    "buildingsInproperties = buildingsInproperties.drop(['index_right'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Keep all addresses columns with the building ID column\n",
    "columns_to_keep = list(buildingsWithaddresses.columns) + ['PropertyID']\n",
    "buildingsInproperties = buildingsInproperties[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildingsInproperties.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildingsInproperties[\"geometry\"] = buildingsInproperties[\"geometry\"].apply(lambda geom: geom.wkb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildingsInproperties[\"geometry\"] = buildingsInproperties[\"geometry\"].apply(lambda geom: geom.wkb)\n",
    "check_duplication(buildingsInproperties, column = 'geometry', drop = False)\n",
    "buildingsInproperties[\"geometry\"] = buildingsInproperties[\"geometry\"].apply(lambda geom: shapely.wkb.loads(geom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# return the polygon geomtry instead of centroids\n",
    "buildingsInproperties['geometry'] = buildings['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(buildingsInproperties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save file\n",
    "buildingsInproperties.to_file(final_buildings + '.shp')\n",
    "buildingsInproperties.to_excel(final_buildings + '.xlsx')\n",
    "buildingsInproperties = buildingsInproperties.to_crs(epsg=4326)\n",
    "buildingsInproperties.to_file(final_buildings + '.geojson', driver='GeoJSON')\n",
    "# save files to database\n",
    "# write_to_postgis(buildingsInproperties, final_buildings, engine, primary_keys = ['BuildingID'], \n",
    "#                  foreign_keys = ['PropertyID'], reference_keys = ['PropertyID'], \n",
    "#                  reference_table_name = [final_properties])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildingsInproperties= gpd.read_file(final_buildings + '.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save file\n",
    "df_obj = buildingsInproperties.select_dtypes(['object'])\n",
    "buildingsInproperties[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "#buildingsInproperties.drop(columns = 'FNR', inplace = True)\n",
    "#buildingsInproperties.to_file(final_buildings + '.shp')\n",
    "#buildingsInproperties.to_excel(final_buildings + '.xlsx')\n",
    "buildingsInproperties = buildingsInproperties.to_crs(epsg=4326)\n",
    "buildingsInproperties.to_file(final_buildings + '.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save addresses shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = gpd.read_file(final_buildings + '.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyproj\n",
    "# pyproj.datadir.set_data_dir(r'C:\\Users\\akm03\\.conda\\envs\\new_env_geo\\share\\proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInproperties = gpd.sjoin(addresses, properties[['PropertyID','geometry']], op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join with properties to link each address to one. Some addresses are outside the building polygon and could\n",
    "# be discarded \n",
    "addressesInproperties = gpd.sjoin(addresses, properties[['PropertyID','geometry']], op='within')\n",
    "addressesInproperties.sort_index(inplace=True)\n",
    "addressesInproperties = addressesInproperties.drop(['index_right'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInproperties[\"geometry\"] = addressesInproperties[\"geometry\"].apply(lambda geom: geom.wkb)\n",
    "check_duplication(addressesInproperties, column = 'geometry', drop = False)\n",
    "# convert back to shapely geometry\n",
    "addressesInproperties[\"geometry\"] = addressesInproperties[\"geometry\"].apply(lambda geom: shapely.wkb.loads(geom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addressesInproperties = addressesInproperties.to_crs(epsg=4326)\n",
    "# how = 'left' to keep all records even those who are not spatial joined.\n",
    "addressesInbuildings = gpd.sjoin(addressesInproperties, buildings[['BuildingID','geometry']], \n",
    "                                 op='within', how='left')\n",
    "addressesInbuildings.sort_index(inplace=True)\n",
    "# addressesInbuildings = addressesInbuildings.drop(['index_right', 'FNR_x', 'FNR_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(addressesInproperties), len(addresses), len(addressesInbuildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplication(addressesInbuildings, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInbuildings['BuildingID'] = addressesInbuildings['BuildingID_right']\n",
    "addressesInbuildings = addressesInbuildings.drop(['BuildingID_left', 'Temp', 'index_right', 'BuildingID_right'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInbuildings = gpd.read_file(final_addresses + '.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInbuildings = addressesInbuildings.rename(columns = {'address_id':'AddressID'})\n",
    "addressesInbuildings = addressesInbuildings[['TableType','Street', 'AdrPlace', 'PostNb', 'PostOffice',\n",
    "                                             'Municipal', 'TRAKT', 'BLOCK', 'ENHET', \n",
    "                                              'County','Commune', 'AdrAreaTp', \n",
    "                                             'AddressID', 'PropertyID', 'BuildingID','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInbuildings['BuildingID'] = addressesInbuildings['BuildingID'].fillna(0).astype(int)\n",
    "addressesInbuildings['PostNb'] = addressesInbuildings['PostNb'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressesInbuildings = gpd.GeoDataFrame(addressesInbuildings, geometry=addressesInbuildings['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the new addresses shapefile\n",
    "# addressesInbuildings = addressesInbuildings.to_crs(epsg=3006)\n",
    "addressesInbuildings.to_file(final_addresses + '.shp')\n",
    "addressesInbuildings.to_excel(final_addresses + '.xlsx')\n",
    "\n",
    "addressesInbuildings = addressesInbuildings.to_crs(epsg=4326)\n",
    "addressesInbuildings.to_file(final_addresses + '.geojson', driver='GeoJSON')\n",
    "# save files to database\n",
    "# write_to_postgis(addressesInbuildings, final_addresses, engine, primary_keys = ['AddressID'], \n",
    "#                  foreign_keys = ['BuildingID','PropertyID'], reference_keys = ['BuildingID','PropertyID'], \n",
    "#                  reference_table_name = [final_buildings, final_properties])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
